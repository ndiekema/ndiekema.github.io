<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Nathan Diekema">
        <title>Nathan's Projects</title>
        <link rel="icon" type="image/x-icon" href="/images/favicon.ico?">
        <link rel="stylesheet" href="/style.css">
        <script src="https://kit.fontawesome.com/4ec81195c8.js" crossorigin="anonymous"></script>
    </head>
<body>
<div class="sub-header">
    <div class="container">
        <nav class="fixed-nav-bar">
            <a href="/index.html"><img src="/images/nd-logo.png" class="logo"></a>
            <ul id="sidemenu">
                <li><a href="/index.html">Home</a></li>
                <li><a href="/about.html">About</a></li>
                <li><a href="/experience.html">Experience</a></li>
                <li><a href="/projects/">Projects</a></li>
                <li><a href="/projects/#contact">Contact</a></li>
                <i class="fa-solid fa-xmark" onclick="closemenu()"></i>
            </ul>
            <i class="fa-solid fa-bars" onclick="openmenu()"></i>
        </nav>
    </div>
    <h1>My Projects</h1>
</div>

<div class="project-page">
    <div class="container">
        <h1 class="page-title">Vegetable Classifier Using CNN</h1>
        <hr>
        <h3>Overview</h3>
        <p>In this project, I built an effective image classifier for the most common vegetables found across the globe. For image
        classification, I employed the use of a Convolutional Neural Network (CNN) in tandem with a few popular preprocessing
        steps. This project was purely meant as a learning experience so there is no defining problem statement to support this
        project. Instead, my goal was to tune and improve my model to maximize performance. The final iteration achieved a
        training accuracy of 96.73%.
        </p>
        <h3>The Data</h3>
        <p>To start, let's talk about the data. The dataset used can be found on Kaggle <a href="https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset" style="text-decoration: none">here</a>. The data consists of 15 types of
        common vegetables found throughout the world. The vegetables are- bean, bitter gourd, bottle gourd, brinjal, broccoli,
        cabbage, capsicum, carrot, cauliflower, cucumber, papaya, potato, pumpkin, radish and tomato. A total of 21000 images
        from 15 classes are used where each class contains 1400 images of size 224x224 and in *.jpg format. The dataset split
        70% for training, 15% for validation, and 15% for testing purpose.
        </p>
        <img src="/images/vclassifier-data.png" alt="">
        <h3>Image Processing & Preparation</h3>
        <p>
            To combat overfitting we're going to do a couple things. First, we're going to generate additional training data from
            existing examples by augmenting them using random transformations of existing images. This is done by randomly rotating
            the image and altering the contrast. Second, we're going to implement dropout layers in our CNN model. Applying dropout
            to a layer randomly drops out (by setting the activation to zero) a number of output units from the layer during the
            training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This
            means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.
        </p>
        <img src="/images/vclassifier-augmented.png" alt="">
        <h3>Model Design and Training</h3>
        <p>
            As discussed earlier, the first layers of the model involve image processing steps (normalization & augmentation). This
            is followed by 3 convolutional, each followed by a pooling and dropout layer. Lastly, the input is flattened and passed
            through a final dense layer. The optimizer chosen to train the model was Adam. The model was trained for 10 epochs, with
            a batch size of 32. An early stopping callback was implemented to mitigate the chance of overfitting. The comparison of
            loss and accuracy between the training and validation datasets can be seen below. I typically would have tried training
            it for more epochs but my RAM was limited and I didn't want to compromise image resolution.
        </p>
        <img src="/images/vclassifier-lossgraph.png" alt="">
        <p>
            As you can see, there is minimal overfitting, training and validation accuracy & loss are closely aligned. An indicator
            of overfitting would be if validation accuracy or loss stalls out while training accuracy continues to improve. When
            this happens it's good practice to reduce the number of epochs, add dropout layers to the model, or try to make the
            training set more diverse. In fact, we should probably run this model for more epochs to test how far we could go before
            overfitting (and we could probably increase performance) but Google Colab is limiting my RAM so more epochs will
            probably crash the runtime.
        </p>
        <h3>Evaluation & Results</h3>
        <p>
            The final iteration of the CNN model achieved an accuracy of 96.73%. Below you can see the classification accuracy specific
            to each class in addition to a confusion matrix. The model did an all around good job but it was clearly better at
            recognizing some vegetables more than others The confusion matrix helps make sense of which classes were getting mixed
            up with each other. For obvious reasons, the vegetables with similar color schemes and shapes got mixed up more often than others.
            For instance, the bottle gourd and papaya have a very similar shape and color. Overall though, the classifier was pretty accurate
            across the board, effectively classifying each vegetable with comparable accuracies. This is even more impressive when considering
            the fact that the this dataset contains vegetables in differing forms (ripe, unripe, picked, still on the plant, busy backgrounds, 
            etc.). This is important when considering the robustness of the classifier because it will be able to accurately classify vegetables
            while accounting for "real world" variance.
        </p>
        <img src="/images/vclassifier-confusionmatrix.png" alt="">
        <br>
        <img src="/images/vclassifier-results.png" alt="">
        <p>
            In the future, I want to compare the performance of this CNN to that of a ResNet and VGG16 architectures. However, these
            model designs are both much more computationally expensive and my current computer would have difficulty training either
            of them. 
        </p>
        <div class="pdf-link">
            <a href="/projects/" class="btn btn2" title="Go back to projects"><i class="fa-solid fa-arrow-left"></i></a>
            <a href="" class="btn btn2" target="_blank" rel="noopener noreferrer"><i class="fa-brands fa-github"></i></a>
        </div>
    </div>
</div>

<!-- ----------footer----------- -->
<div class="footer">
    <div class="container">
        <div class="footer-nav">
            <a href="/index.html">Home</a>
            <a href="/about.html">About</a>
            <a href="/experience.html">Experience</a>
            <a href="/projects/">Projects</a>
            <a href="/index.html#contact">Contact</a>
        </div>
    </div>
    <div class="copyright">
        <p>2022 Â© Nathan Diekema. Made with <i class="fa-solid fa-heart"></i></p>
    </div>
</div>

</body>
</html>